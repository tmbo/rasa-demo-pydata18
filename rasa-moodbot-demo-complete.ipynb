{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kO9wt2g3okLS"
   },
   "source": [
    "# Conversational AI with Rasa\n",
    "![alt text](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTaX3LNhGcAe1HnPZSuWS0oH6af0LJHXcH7If1sQgLCFAT1chNGFg)\n",
    "\n",
    "This notebook is going to be the basis for my workshop at the PyData 2018 Amsterdam workshop. If you have any questions, please let me know!\n",
    "\n",
    "You'll build a relatively simple bot, that just asks you about your mood and tries to cheer you up if you're feeling a bit down. \n",
    "\n",
    "The tutorial consists of three parts:\n",
    "\n",
    "\n",
    "*   Part 0: Installation and preparations\n",
    "*   Part 1: You'll start with a basic bot that can only understand natural language but no dialogues.\n",
    "*   Part 2: You'll add the abilitiy to understand multiturn dialogues.\n",
    "*   Part 3: I'll give you further resources so you can extend this simple demo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Installation\n",
    "\n",
    "### Let's start with jupyter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def pprint(o):\n",
    "    # small helper to make dict dumps a bit prettier\n",
    "    print(json.dumps(o, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y4miuS-TqYcn"
   },
   "source": [
    "### Installation of Rasa\n",
    "First you'll have to install Rasa Core and NLU in this notebook if you already have them installed in your env, you can just skip this. But make sure you also have the spacy model installed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3607
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 58315,
     "status": "ok",
     "timestamp": 1521575035242,
     "user": {
      "displayName": "Ricardo Wölker",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115384113157413623365"
     },
     "user_tz": 0
    },
    "id": "X_2-sKgo_qyl",
    "outputId": "b947c702-75fa-406d-d21d-a691dcb5236d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "python = sys.executable\n",
    "\n",
    "# In your environment run:\n",
    "!{python} -m pip install -U rasa_core==0.9.0a7 rasa_nlu[spacy];\n",
    "\n",
    "# as well as install a language model:\n",
    "!{python} -m spacy download en_core_web_md;\n",
    "!{python} -m spacy link --force en_core_web_md en;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the correct versions are installed (should be rasa_nlu: 0.12.3 rasa_core: 0.9.0a7) and the spacy model is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasa_nlu\n",
    "import rasa_core\n",
    "import spacy\n",
    "\n",
    "print(\"rasa_nlu: {} rasa_core: {}\".format(rasa_nlu.__version__, rasa_core.__version__))\n",
    "print(\"Loading spaCy language model...\")\n",
    "print(spacy.load(\"en\")(\"Hello world!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some additional Tools needed\n",
    "To do some of the visualizations you will also need graphviz. If you don't have graphviz installed, and this doesn't work: don't worry. I'll show you the graph and besides that visualization everything else will work.\n",
    "\n",
    "Try installing with anyone of these (or adapt to your operating system):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get -qq install -y graphviz libgraphviz-dev pkg-config;\n",
    "!brew install graphviz;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and another python package and we are ready to go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install pygraphviz;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cNa5KHl1nzhT"
   },
   "source": [
    "## Part 1: Add natural language understanding\n",
    "\n",
    "First thing our bot is going to learn is how to understand user messages. To do that, you're going to build a first version of your language understanding model with Rasa NLU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GAlnWyGRwcwO"
   },
   "source": [
    "### Language Understanding\n",
    "\n",
    "\n",
    "Lets create some training data here, grouping user messages by their `intent`s. The intent describes what the messages *mean*. [More information about the data format](https://nlu.rasa.com/dataformat.html#markdown-format). This is the training data for our NLU model, one example per line. Entities are labeled using the markdown link syntex: `[entity value](entity_type)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 864,
     "status": "ok",
     "timestamp": 1521380057973,
     "user": {
      "displayName": "Alexander Weidauer",
      "photoUrl": "//lh6.googleusercontent.com/-j4xnI5_PFWA/AAAAAAAAAAI/AAAAAAAAAAo/wPT2w5Bl3xg/s50-c-k-no/photo.jpg",
      "userId": "100444450157165144272"
     },
     "user_tz": -60
    },
    "id": "V6KHWT2zeEh5",
    "outputId": "bab4845d-4ebc-4b9b-f8d9-2f701504a9c0"
   },
   "outputs": [],
   "source": [
    "nlu_md = \"\"\"\n",
    "## intent:greet\n",
    "- hey I am [Peter](PERSON)\n",
    "- hello there I am [Hans](PERSON)\n",
    "- hi I am [Tom](PERSON)\n",
    "- hello there\n",
    "- good morning\n",
    "- good evening\n",
    "- moin\n",
    "- hey there\n",
    "- let's go\n",
    "- hey dude\n",
    "- goodmorning\n",
    "- goodevening\n",
    "- good afternoon\n",
    "\n",
    "## intent:goodbye\n",
    "- cu\n",
    "- good by\n",
    "- cee you later\n",
    "- good night\n",
    "- good afternoon\n",
    "- bye\n",
    "- goodbye\n",
    "- have a nice day\n",
    "- see you around\n",
    "- bye bye\n",
    "- see you later\n",
    "\n",
    "## intent:mood_affirm\n",
    "- yes\n",
    "- indeed\n",
    "- of course\n",
    "- that sounds good\n",
    "- correct\n",
    "\n",
    "## intent:mood_deny\n",
    "- no\n",
    "- never\n",
    "- I don't think so\n",
    "- don't like that\n",
    "- no way\n",
    "- not really\n",
    "\n",
    "## intent:mood_great\n",
    "- perfect\n",
    "- very good\n",
    "- great\n",
    "- amazing\n",
    "- feeling like a king\n",
    "- wonderful\n",
    "- I am feeling very good\n",
    "- I am great\n",
    "- I am amazing\n",
    "- I am going to save the world\n",
    "- super\n",
    "- extremely good\n",
    "- so so perfect\n",
    "- so good\n",
    "- so perfect\n",
    "\n",
    "## intent:mood_unhappy\n",
    "- my day was horrible\n",
    "- I am sad\n",
    "- I don't feel very well\n",
    "- I am disappointed\n",
    "- super sad\n",
    "- I'm so sad\n",
    "- sad\n",
    "- very sad\n",
    "- unhappy\n",
    "- bad\n",
    "- very bad\n",
    "- awful\n",
    "- terrible\n",
    "- not so good\n",
    "- not very good\n",
    "- extremly sad\n",
    "- so saad\n",
    "- so sad\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To properly train your NLU model, you also need to define what is part of that model. Rasa NLU uses a similar pipeline concept as sklearn does. All the components that are listed in the pipeline will be trained one after another and everyone of them contributes its part to the structured data extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \"nlp_spacy\"                   # loads the spacy language model\n",
    "- name: \"tokenizer_spacy\"             # splits the sentence into tokens\n",
    "- name: \"ner_spacy\"                   # uses the pretrained spacy NER model\n",
    "- name: \"intent_featurizer_spacy\"     # transform the sentence into a vector representation\n",
    "- name: \"intent_classifier_sklearn\"   # uses the vector representation to classify using SVM\n",
    "\"\"\" \n",
    "\n",
    "%store config > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1xeXgpdwzOAl"
   },
   "source": [
    "### Train the Rasa NLU Model\n",
    "\n",
    "You're going to train a model to recognise these intents, so that when you send a message like \"hello\" to your bot, it will recognise this as a `\"greet\"` intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2821,
     "status": "ok",
     "timestamp": 1521380062879,
     "user": {
      "displayName": "Alexander Weidauer",
      "photoUrl": "//lh6.googleusercontent.com/-j4xnI5_PFWA/AAAAAAAAAAI/AAAAAAAAAAo/wPT2w5Bl3xg/s50-c-k-no/photo.jpg",
      "userId": "100444450157165144272"
     },
     "user_tz": -60
    },
    "id": "qHsAH49OePcM",
    "outputId": "f840c42d-acf2-4fbf-b439-e5a239ffb32b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "\n",
    "# loading the nlu training samples\n",
    "training_data = load_data(\"nlu.md\")\n",
    "\n",
    "# trainer to educate our pipeline\n",
    "trainer = Trainer(config.load(\"config.yml\"))\n",
    "\n",
    "# train the model!\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# store it for future use\n",
    "model_directory = trainer.persist(\"./models/nlu\", fixed_model_name=\"current\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1xeXgpdwzOAl"
   },
   "source": [
    "### Use & evaluate the NLU model\n",
    "Let's play around with the model and shoot it some messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2821,
     "status": "ok",
     "timestamp": 1521380062879,
     "user": {
      "displayName": "Alexander Weidauer",
      "photoUrl": "//lh6.googleusercontent.com/-j4xnI5_PFWA/AAAAAAAAAAI/AAAAAAAAAAo/wPT2w5Bl3xg/s50-c-k-no/photo.jpg",
      "userId": "100444450157165144272"
     },
     "user_tz": -60
    },
    "id": "qHsAH49OePcM",
    "outputId": "f840c42d-acf2-4fbf-b439-e5a239ffb32b"
   },
   "outputs": [],
   "source": [
    "pprint(interpreter.parse(\"doing great\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of evaluating it by hand, the model can also be evaluated on a test data set (though for simplicity we are going to use the same for test and train):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_nlu.evaluate import run_evaluation\n",
    "\n",
    "run_evaluation(\"nlu.md\", model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tK5os3OinphP"
   },
   "source": [
    "# Part 2: Adding dialogue capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BBF6Nqi9scQE"
   },
   "source": [
    "### Writing Stories\n",
    "\n",
    "A good place to start is by writing a few stories. These are example conversations that Rasa Core will learn from. \n",
    "\n",
    "The format works like this:\n",
    "\n",
    "A story starts with `##` and you can give it a name. \n",
    "lines that start with `*` are messages sent by the user. Although you don't write the *actual* message, but rather the intent (and the entities) that represent what the user *means*. If you don't know about intents and entities, don't worry! We will talk about them more later. \n",
    "Lines that start with `-` are *actions* taken by your bot. In this case all of our actions are just messages sent back to the user, like `utter_greet`, but in general an action can do anything, including calling an API and interacting with the outside world. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 568,
     "status": "ok",
     "timestamp": 1521575049982,
     "user": {
      "displayName": "Ricardo Wölker",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115384113157413623365"
     },
     "user_tz": 0
    },
    "id": "zamaNW4RsrLe",
    "outputId": "6203e4c3-46a3-4c43-add6-95a70d4a6d50"
   },
   "outputs": [],
   "source": [
    "stories_md = \"\"\"\n",
    "## happy path               <!-- name of the story - just for debugging -->\n",
    "* greet              \n",
    "  - utter_greet\n",
    "* mood_great               <!-- user utterance, in format intent[entities] -->\n",
    "  - utter_happy\n",
    "* mood_affirm\n",
    "  - utter_happy\n",
    "* mood_affirm\n",
    "  - utter_goodbye\n",
    "  \n",
    "## sad path 1               <!-- this is already the start of the next story -->\n",
    "* greet\n",
    "  - utter_greet             <!-- action the bot should execute -->\n",
    "* mood_unhappy\n",
    "  - action_retrieve_image\n",
    "  - utter_cheer_up\n",
    "  - utter_did_that_help\n",
    "* mood_affirm\n",
    "  - utter_happy\n",
    "\n",
    "## sad path 2\n",
    "* greet\n",
    "  - utter_greet\n",
    "* mood_unhappy\n",
    "  - action_retrieve_image\n",
    "  - utter_cheer_up\n",
    "  - utter_did_that_help\n",
    "* mood_deny\n",
    "  - utter_goodbye\n",
    "  \n",
    "## strange user\n",
    "* mood_affirm\n",
    "  - utter_happy\n",
    "* mood_affirm\n",
    "  - utter_unclear\n",
    "\n",
    "## say goodbye\n",
    "* goodbye\n",
    "  - utter_goodbye\n",
    "\n",
    "## fallback\n",
    "- utter_unclear\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > stories.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fs3nOUzBsqrG"
   },
   "source": [
    "### Defining a Domain\n",
    "\n",
    "The domain specifies the universe that your bot lives in. You should list all of the intents and actions that show up in your stories. \n",
    "This is also the place to write templates, which contain the messages your bot can send back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1521575053606,
     "user": {
      "displayName": "Ricardo Wölker",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115384113157413623365"
     },
     "user_tz": 0
    },
    "id": "WB6eIXVkAOSX",
    "outputId": "566b7c42-3772-4754-df55-19874543108c"
   },
   "outputs": [],
   "source": [
    "domain_yml = \"\"\"\n",
    "intents:\n",
    "- greet\n",
    "- goodbye\n",
    "- mood_affirm\n",
    "- mood_deny\n",
    "- mood_great\n",
    "- mood_unhappy\n",
    "\n",
    "slots:\n",
    "  img_api_response:\n",
    "    type: unfeaturized\n",
    "\n",
    "actions:\n",
    "- utter_greet\n",
    "- utter_cheer_up\n",
    "- utter_did_that_help\n",
    "- utter_happy\n",
    "- utter_goodbye\n",
    "- utter_unclear\n",
    "- __main__.ApiAction\n",
    "\n",
    "templates:\n",
    "  utter_greet:\n",
    "  - text: \"Hey! How are you?\"\n",
    "\n",
    "  utter_cheer_up:\n",
    "  - text: \"Here is something to cheer you up: {img_api_response}\"\n",
    "\n",
    "  utter_did_that_help:\n",
    "  - text: \"Did that help you?\"\n",
    "\n",
    "  utter_unclear:\n",
    "  - text: \"I am not sure what you are aiming for.\"\n",
    "  \n",
    "  utter_happy:\n",
    "  - text: \"Great carry on!\"\n",
    "\n",
    "  utter_goodbye:\n",
    "  - text: \"Bye\"\n",
    "\"\"\"\n",
    "\n",
    "%store domain_yml > domain.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Custom API methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, you not only want to send back messages to the user, but you also want to call an API or run some code. YOu can create custom actions that will be called once the bots ML model predicts them. You'll use that to fetch a random image from a remote server (we are not actually fetching it here, but we could ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_core.actions import Action\n",
    "from rasa_core.events import SlotSet\n",
    "\n",
    "import requests\n",
    "\n",
    "class ApiAction(Action):\n",
    "    def name(self):\n",
    "        return \"action_retrieve_image\"\n",
    "\n",
    "    def run(self, dispatcher, tracker, domain):\n",
    "        dispatcher.utter_message(\"looking for a good img\")\n",
    "        url = \"https://picsum.photos/200/300/?random\"\n",
    "        return [SlotSet(\"img_api_response\", url)]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qWALQbCdwGxK"
   },
   "source": [
    "### Pro Tip: Visualising the Training Data\n",
    "\n",
    "You can visualise the stories to get a sense of how the conversations go. This is usually a good way to see if there are any stories which don't make sense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 895
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2808,
     "status": "ok",
     "timestamp": 1521380138202,
     "user": {
      "displayName": "Alexander Weidauer",
      "photoUrl": "//lh6.googleusercontent.com/-j4xnI5_PFWA/AAAAAAAAAAI/AAAAAAAAAAo/wPT2w5Bl3xg/s50-c-k-no/photo.jpg",
      "userId": "100444450157165144272"
     },
     "user_tz": -60
    },
    "id": "zl6vtV72BDaV",
    "outputId": "2468f1bf-3fd0-42f0-9338-8f48c8cad3dd"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "agent = Agent('domain.yml')\n",
    "agent.visualize(\"stories.md\", \"story_graph.png\", max_history=2)\n",
    "Image(filename=\"story_graph.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQxY6m6kvlj3"
   },
   "source": [
    "### Training your Dialogue Model\n",
    "\n",
    "Now comes the fun part! We're going to show Rasa Core the stories we wrote above, and train a model on these examples. \n",
    "In this case, the model is a neural network implemented in Keras which learns to predict which action to take next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 14025
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12554,
     "status": "ok",
     "timestamp": 1521575068686,
     "user": {
      "displayName": "Ricardo Wölker",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "115384113157413623365"
     },
     "user_tz": 0
    },
    "id": "PKV49d7tAxmS",
    "outputId": "ccb26bea-5be8-48f7-a88e-d70a6e4a1733"
   },
   "outputs": [],
   "source": [
    "from rasa_core.policies import FallbackPolicy, KerasPolicy, MemoizationPolicy\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "# this will catch predictions the model isn't very certain about\n",
    "# there is a threshold for the NLU predictions as well as the action predictions\n",
    "fallback = FallbackPolicy(fallback_action_name=\"utter_unclear\",\n",
    "                          core_threshold=0.2,\n",
    "                          nlu_threshold=0.6)\n",
    "\n",
    "agent = Agent('domain.yml', policies=[MemoizationPolicy(), KerasPolicy(), fallback])\n",
    "\n",
    "# loading our neatly defined training dialogues\n",
    "training_data = agent.load_data('stories.md')\n",
    "\n",
    "agent.train(\n",
    "    training_data,\n",
    "    validation_split=0.0,\n",
    "    epochs=400\n",
    ")\n",
    "\n",
    "agent.persist('models/dialogue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FSjCEdvlzfSR"
   },
   "source": [
    "### Starting up the bot (with NLU)\n",
    "\n",
    "Now that we've trained the dialogue **and** language understanding models and saved them, we can start up an `Agent` which will handle conversations for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1799,
     "status": "ok",
     "timestamp": 1521380071327,
     "user": {
      "displayName": "Alexander Weidauer",
      "photoUrl": "//lh6.googleusercontent.com/-j4xnI5_PFWA/AAAAAAAAAAI/AAAAAAAAAAo/wPT2w5Bl3xg/s50-c-k-no/photo.jpg",
      "userId": "100444450157165144272"
     },
     "user_tz": -60
    },
    "id": "Ywxs0ljHgkLm",
    "outputId": "e11a8abd-70f6-41c5-ccd1-a7cba7146ce9"
   },
   "outputs": [],
   "source": [
    "from rasa_core.agent import Agent\n",
    "agent = Agent.load('models/dialogue', interpreter=model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5MnGuFRpzzBh"
   },
   "source": [
    "### Talking to the Bot (with NLU)\n",
    "\n",
    "We can start talking to the bot in natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1340
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57365,
     "status": "error",
     "timestamp": 1521380132537,
     "user": {
      "displayName": "Alexander Weidauer",
      "photoUrl": "//lh6.googleusercontent.com/-j4xnI5_PFWA/AAAAAAAAAAI/AAAAAAAAAAo/wPT2w5Bl3xg/s50-c-k-no/photo.jpg",
      "userId": "100444450157165144272"
     },
     "user_tz": -60
    },
    "id": "t_4zHDsgkbno",
    "outputId": "57473fce-7184-45d1-f2b2-470bfc84244e"
   },
   "outputs": [],
   "source": [
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    responses = agent.handle_message(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the dialogue model\n",
    "As with the NLU model, instead of just subjectively testing the model, we can also evaluate the model on a dataset. You'll be using the training data set again, but usually you'd use a test data set separate from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_core.evaluate import run_story_evaluation\n",
    "\n",
    "run_story_evaluation(\"stories.md\", \"models/dialogue\", \n",
    "                     nlu_model_path=None, \n",
    "                     max_stories=None, \n",
    "                     out_file_plot=\"story_eval.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive learning\n",
    "Unfortunately, this doesn't work in jupyter yet. Hence, we going to do this on the command line. [The repository](https://github.com/tmbo/rasa-demo-pydata18)  contains a makefile with the instructions to run the interactive learning. So go ahead and run `make interactive` on the commandline (make sure your shell is in the righht virtual env)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m7VUXU6Cn5R-"
   },
   "source": [
    "# Part 3: Next steps\n",
    "\n",
    "Great job! You've built your first bot that uses Machine Learning to manage dialogues. As a next step, we'd suggest you start building your own bot. Here are a few useful links:\n",
    "\n",
    "\n",
    "\n",
    "*   Install the Rasa Stack on your machine [here](https://core.rasa.ai/installation.html)\n",
    "*   Checkout more of the Docs: [NLU](https://nlu.rasa.com) and [Core](https://core.rasa.com)\n",
    "*   Connect to the community in our [Gitter Chat](https://gitter.im/RasaHQ/rasa_core)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Any feedback for this tutorial?* Please shoot me a mail at tom@rasa.com"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "y4miuS-TqYcn",
    "BBF6Nqi9scQE",
    "Fs3nOUzBsqrG",
    "5MnGuFRpzzBh"
   ],
   "default_view": {},
   "name": "Building a Simple Bot with Rasa Stack - Tutorial",
   "provenance": [
    {
     "file_id": "1GutDkDXmfU-nRzNH7Pxxx8YpdvLUw9LO",
     "timestamp": 1521183725373
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
